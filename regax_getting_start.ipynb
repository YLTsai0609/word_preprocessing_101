{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "1. Introduction to regular expressions\n",
    "2. What is a regex pattern and how to compile one?\n",
    "3. How to split a string separated by a regex?\n",
    "4. Finding pattern matches using findall, search and match\n",
    "4.1 What does regex.findall() do?\n",
    "4.2 regex.search() vs regex.match()\n",
    "5. How to substitute one text with another using regex?\n",
    "6. Regex groups\n",
    "7. What is greedy matching in regex?\n",
    "8. Most common regular expression syntax and patterns\n",
    "9. Regular Expressions Examples\n",
    "10. Practice Exercises\n",
    "11. Conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.511248Z",
     "start_time": "2021-03-01T06:20:21.508405Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile('\\s+')\n",
    "# \\s match 任何空白字元\n",
    "# + match 一個獲釋多個以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.517259Z",
     "start_time": "2021-03-01T06:20:21.513575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['101', 'COM', 'Computers', '205', 'MAT', 'Mathematics', '189', 'ENG', 'English']\n",
      "['101', 'COM', 'Computers', '205', 'MAT', 'Mathematics', '189', 'ENG', 'English']\n"
     ]
    }
   ],
   "source": [
    "# 3. How to split a string separated by a regex?\n",
    "# Let’s consider the following piece of text.\n",
    "\n",
    "text = \"\"\"101 COM    Computers\n",
    "205 MAT   Mathematics\n",
    "189 ENG   English\"\"\"\n",
    "\n",
    "\n",
    "sol_1 = re.split('\\s+', text)\n",
    "sol_2 = regex.split(text)\n",
    "print(sol_1, sol_2, sep='\\n')\n",
    "\n",
    "# hint\n",
    "# 使用re.split 方法 - pattern簡單時\n",
    "# 把regex物件先設定好, 在call split方法 - pattern複雜時\n",
    "# split用於分割字串時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.530270Z",
     "start_time": "2021-03-01T06:20:21.520791Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 COM    Computers\n",
      "205 MAT   Mathematics\n",
      "189 ENG   English\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['101', '205', '189']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Finding pattern matches using findall, search and match\n",
    "# Let’s suppose you want to extract all the course numbers, that is, the numbers 101, 205 and 189 alone from the above text. How to do that?\n",
    "\n",
    "print(text)\n",
    "print('-' * 60)\n",
    "regex_num = re.compile('\\d+')\n",
    "regex_num.findall(text)\n",
    "\n",
    "# hint \\d mean digit\n",
    "# + means 一個或多個, * means 0個或多個\n",
    "# findall method 所有發生的情況, 加到list, 用於過濾字串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.537075Z",
     "start_time": "2021-03-01T06:20:21.532472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Position:  17\n",
      "Ending Position:  20\n",
      "205\n",
      "['__class__', '__copy__', '__deepcopy__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'end', 'endpos', 'expand', 'group', 'groupdict', 'groups', 'lastgroup', 'lastindex', 'pos', 're', 'regs', 'span', 'start', 'string']\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "# 4.2 re.search() vs re.match()\n",
    "# As the name suggests, regex.search() searches for the pattern in a given text.\n",
    "\n",
    "# But unlike findall which returns the matched portions of the text as a list, regex.search() returns a particular match object that contains the starting and ending positions of the first occurrence of the pattern.\n",
    "\n",
    "# Likewise, regex.match() also returns a match object. But the difference is, it requires the pattern to be present at the beginning of the text itself.\n",
    "\n",
    "text2 = \"\"\"COM    Computers\n",
    "205 MAT   Mathematics 189\"\"\"\n",
    "\n",
    "regex_num = re.compile('\\d+')\n",
    "s = regex_num.search(text2)\n",
    "print('Starting Position: ', s.start())\n",
    "print('Ending Position: ', s.end())\n",
    "print(text2[s.start():s.end()])\n",
    "print(dir(s))\n",
    "print(s.group())\n",
    "\n",
    "# hint\n",
    "# search, 從字串頭搜尋到字串尾, match出205,\n",
    "# 從group取出\n",
    "# 並且search物件中有方法可以call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.542010Z",
     "start_time": "2021-03-01T06:20:21.538942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "m = regex_num.match(text2)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.548010Z",
     "start_time": "2021-03-01T06:20:21.544245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101   COM \t  Computers\n",
      "205   MAT \t  Mathematics\n",
      "189   ENG  \t  English\n",
      "101 COM Computers 205 MAT Mathematics 189 ENG English\n",
      "101 COM Computers 205 MAT Mathematics 189 ENG English\n"
     ]
    }
   ],
   "source": [
    "# 5. How to substitute one text with another using regex?\n",
    "# To replace texts, use the regex.sub().\n",
    "\n",
    "# Let’s consider the following modified version of the courses text. Here I have added an extra tab after each course code.\n",
    "\n",
    "text = \"\"\"101   COM \\t  Computers\n",
    "205   MAT \\t  Mathematics\n",
    "189   ENG  \\t  English\"\"\"\n",
    "print(text)\n",
    "\n",
    "\n",
    "# replace one or more spaces with single space\n",
    "sol1 = re.sub('\\s+', ' ', text)\n",
    "regex = re.compile('\\s+')\n",
    "sol2 = regex.sub(' ', text)\n",
    "print(sol1, sol2, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.555139Z",
     "start_time": "2021-03-01T06:20:21.552340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 COM Computers\n",
      "205 MAT Mathematics\n",
      "189 ENG English\n"
     ]
    }
   ],
   "source": [
    "# get rid of all extra spaces except newline\n",
    "regex = re.compile('(?!\\n)\\s+')\n",
    "print(regex.sub(' ', text))\n",
    "# hint\n",
    "# ?!\\n 遇到\\n則保留\n",
    "# ?! 否定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.562236Z",
     "start_time": "2021-03-01T06:20:21.558443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['101', '205', '189']\n",
      "['COM', 'MAT', 'ENG']\n",
      "['Computers', 'Mathematics', 'English']\n"
     ]
    }
   ],
   "source": [
    "# 6. Regex groups\n",
    "# Regular expression groups is a very useful feature that lets you extract the desired match objects as individual items.\n",
    "\n",
    "# Suppose I want to extract the course number, code and the name as separate items. Without groups, I will have to write something like this.\n",
    "\n",
    "text = \"\"\"101   COM   Computers\n",
    "205   MAT   Mathematics\n",
    "189   ENG    English\"\"\"\n",
    "\n",
    "# extract all course numbers\n",
    "print(re.findall('[0-9]+', text))\n",
    "\n",
    "# extract all course codes\n",
    "print(re.findall('[A-Z]{3}', text))\n",
    "\n",
    "# extract all course names\n",
    "\n",
    "print(re.findall('[A-Za-z]{4,}', text))\n",
    "\n",
    "# 符合0個以上 *\n",
    "# 符合1個以上 +\n",
    "# 符合0個或1個 ?\n",
    "# 符合特定數目 {n}\n",
    "# 符合特定數目以上 {n,}\n",
    "# 符合特定數目以下 {,n}\n",
    "# 符合特定數目之間 {n,p}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.567930Z",
     "start_time": "2021-03-01T06:20:21.563778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'COM', 'Computers'),\n",
       " ('5', 'MAT', 'Mathematics'),\n",
       " ('9', 'ENG', 'English')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the course text pattern groups and extract\n",
    "course_pattern = '([0-9])\\s*([A-Z]{3})\\s*([A-Za-z]{4,})'\n",
    "re.findall(course_pattern, text)\n",
    "# hint\n",
    "# 找出pattern, 用\\s*切分開, 放在turple,list中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.573532Z",
     "start_time": "2021-03-01T06:20:21.570363Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['< body>Regex Greedy Matching Example < /body>']\n"
     ]
    }
   ],
   "source": [
    "# 7. What is greedy matching in regex?\n",
    "# The default behavior of regular expressions is to be greedy. That means it tries to extract as much as possible until it conforms to a pattern even when a smaller part would have been syntactically sufficient.\n",
    "\n",
    "# Let’s see an example of a piece of HTML, where I want to retrieve the HTML tag.\n",
    "\n",
    "text = \"< body>Regex Greedy Matching Example < /body>\"\n",
    "print(re.findall('<.*>', text))\n",
    "\n",
    "# hint 預設搜尋為greddy搜尋，能搜尋多少，就搜尋多少\n",
    "# 原本預期 抓取出 < body>這個tag\n",
    "# 結果全抓, <body ..........< /body>\n",
    "# regex . means 任何一個字元, 除了\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.579324Z",
     "start_time": "2021-03-01T06:20:21.575685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 're.Match'>\n",
      "< body>\n"
     ]
    }
   ],
   "source": [
    "# 只想抓1個, 或是幾個 lazy-matching\n",
    "re.findall('<.*?>', text)\n",
    "\n",
    "# 使用regex-group取出第一個\n",
    "\n",
    "s = re.search('<.*?>', text)\n",
    "print(type(s), s.group(), sep='\\n')\n",
    "# hint\n",
    "# reg-group可以抓出其中幾個\n",
    "# re.search return a SER_Match object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './images/regex1.png'>\n",
    "<img src = './images/regex2.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.584672Z",
     "start_time": "2021-03-01T06:20:21.581491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m', 'a', 'c', 'h', 'i', 'n', 'e', 'l', 'e', 'a', 'r', 'n', 'i', 'n', 'g', 'p', 'l', 'u', 's', '.', 'c', 'o', 'm']\n",
      "['mac', 'hin', 'ele', 'arn', 'ing', 'plu', 's.c']\n"
     ]
    }
   ],
   "source": [
    "# 9.1. Any character except for a new line\n",
    "text = 'machinelearningplus.com'\n",
    "print(re.findall('.', text))\n",
    "print(re.findall('(...)', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.589685Z",
     "start_time": "2021-03-01T06:20:21.586474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.']\n",
      "['m', 'a', 'c', 'h', 'i', 'n', 'e', 'l', 'e', 'a', 'r', 'n', 'i', 'n', 'g', 'p', 'l', 'u', 's', 'c', 'o', 'm']\n"
     ]
    }
   ],
   "source": [
    "# 9.2. A period\n",
    "text = 'machinelearningplus.com'\n",
    "text2 = 'abcabcabcabcabc'\n",
    "print(re.findall('\\.', text))\n",
    "print(re.findall('[^\\.]', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.593733Z",
     "start_time": "2021-03-01T06:20:21.591080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '2015']\n",
      "['01', '2015']\n"
     ]
    }
   ],
   "source": [
    "# 9.3. Any digit\n",
    "text = '01, Jan 2015'\n",
    "print(re.findall('[0-9]{2,}', text))\n",
    "print(re.findall('\\d+', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.599166Z",
     "start_time": "2021-03-01T06:20:21.595515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[', Jan ']\n"
     ]
    }
   ],
   "source": [
    "# 9.4. Anything but a digit\n",
    "text = '01, Jan 2015'\n",
    "print(re.findall('\\D+', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.603731Z",
     "start_time": "2021-03-01T06:20:21.600876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', 'Jan', '2015']\n",
      "['01', 'Jan', '2015']\n"
     ]
    }
   ],
   "source": [
    "# 9.5. Any character, including digits\n",
    "text = '01, Jan 2015'\n",
    "print(re.findall('[0-9A-Za-z]+', text))\n",
    "print(re.findall('\\w+', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.608299Z",
     "start_time": "2021-03-01T06:20:21.605586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[', ', ' ']\n"
     ]
    }
   ],
   "source": [
    "# 9.6. Anything but a character\n",
    "text = '01, Jan 2015'\n",
    "print(re.findall('\\W+', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.616227Z",
     "start_time": "2021-03-01T06:20:21.613862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jan']\n"
     ]
    }
   ],
   "source": [
    "# 9.7. Collection of characters\n",
    "text = '01, Jan 2015'\n",
    "print(re.findall('[a-zA-Z]+', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.622295Z",
     "start_time": "2021-03-01T06:20:21.619168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015']\n",
      "['01', '2015']\n"
     ]
    }
   ],
   "source": [
    "# 9.8. Match something upto ‘n’ times\n",
    "text = '01, Jan 2015'\n",
    "print(re.findall('\\d{4}', text))\n",
    "print(re.findall('\\d{2,4}', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.626209Z",
     "start_time": "2021-03-01T06:20:21.623832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coooooooool']\n"
     ]
    }
   ],
   "source": [
    "# 9.9. Match 1 or more occurrences\n",
    "print(re.findall(r'Co+l', 'So Coooooooool'))\n",
    "# r表示為非轉譯之原始字符，及忽略反斜槓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:22:24.118598Z",
     "start_time": "2021-03-01T06:22:24.113994Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['\\\\section']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 9.10 轉譯符號\n",
    "# 必須用\\轉譯\n",
    "print(re.findall(r'\\section', '\\section')) # doesn't work\n",
    "print(re.findall(r'\\\\section', '\\section')) # will work\n",
    "print(re.findall('\\section', '\\section')) # will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.634793Z",
     "start_time": "2021-03-01T06:20:21.631900Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toy']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 9.12. Match word boundaries\n",
    "# Word boundaries \\b are commonly used to detect and match the beginning or end of a word. That is, one side is a word character and the other side is whitespace and vice versa.\n",
    "\n",
    "# For example, the regex \\btoy will match the ‘toy’ in ‘toy cat’ and not in ‘tolstoy’. In order to match the ‘toy’ in ‘tolstoy’, you should use toy\\b\n",
    "\n",
    "re.findall(r'\\btoy\\b', 'play toy broke toys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.640327Z",
     "start_time": "2021-03-01T06:20:21.636446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('zuck26', 'facebook', 'com'),\n",
       " ('page33', 'google', 'com'),\n",
       " ('jeff42', 'amazon', 'com')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Practice Exercises\n",
    "# 1. Extract the user id, domain name and suffix from the following email addresses.\n",
    "\n",
    "emails = \"\"\"zuck26@facebook.com\n",
    "page33@google.com\n",
    "jeff42@amazon.com\"\"\"\n",
    "\n",
    "pat = re.compile(r'(\\w+)@(\\w+).([A-Za-z]{2,4})')\n",
    "re.findall(pat, emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.644943Z",
     "start_time": "2021-03-01T06:20:21.642132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Betty', 'bought', 'bit', 'butter', 'But', 'butter', 'bitter', 'bought', 'better', 'butter', 'bitter', 'butter', 'better']\n"
     ]
    }
   ],
   "source": [
    "# 2. Retrieve all the words starting with ‘b’ or ‘B’ from the following text.\n",
    "\n",
    "text = \"\"\"Betty bought a bit of butter, But the butter was so bitter, So she bought some better butter, To make the bitter butter better.\"\"\"\n",
    "print(re.findall(r'\\bB\\w+', text, flags=re.IGNORECASE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.650989Z",
     "start_time": "2021-03-01T06:20:21.646662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A  very   very  irregular sentence'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Split the following irregular sentence into words\n",
    "sentence = \"\"\"A, very   very; irregular_sentence\"\"\"\n",
    "\" \".join(re.split(r'[;,_\\s+]', sentence))\n",
    "# hint :,_超過一個空白等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:21.659712Z",
     "start_time": "2021-03-01T06:20:21.652836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good advice What I would do differently if I wa learning to code today'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Clean up the following tweet so that it contains only the user’s message. That is, remove all URLs, hashtags, mentions, punctuations, RTs and CCs.\n",
    "tweet = '''Good advice! RT @TheNextWeb: What I would do differently if I was learning to code today http://t.co/lbwej0pxOd cc: @garybernhardt #rstats'''\n",
    "\n",
    "\n",
    "def cleaning_text_eng(text):\n",
    "    '''\n",
    "    英文的清理和中文的清理會不同\n",
    "    '''\n",
    "    tweet = re.sub(r'http\\S+\\s*', '', text)  # URLs http + 非空白一個以上 + 空白0個以上\n",
    "    tweet = re.sub(r'RT|cc', '', tweet)  # RT and CC\n",
    "    tweet = re.sub(r'#\\S+', '', tweet)  # hashtag # + 非空白字元\n",
    "    tweet = re.sub(r'@\\S+', '', tweet)  # hashtag @ + 非空白字元\n",
    "    tweet = re.sub(r\"\"\"[%s!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\"\"\",\n",
    "                   '',\n",
    "                   tweet)  # 標點符號\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)  # 額外的空白字元\n",
    "    tweet = tweet.strip()\n",
    "    return tweet\n",
    "\n",
    "\n",
    "clean_tweet = cleaning_text_eng(tweet)\n",
    "clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:22.501835Z",
     "start_time": "2021-03-01T06:20:21.661693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML>\n",
      "<HEAD>\n",
      "<TITLE>Your Title Here</TITLE>\n",
      "</HEAD>\n",
      "\n",
      "<BODY>\n",
      "<HR>\n",
      "<a href=\"http://someurl.com\">Link Name</a>\n",
      "<H1>This is a Header</H1>\n",
      "<H2>This is a Medium Header</H2>\n",
      "<P>This is a new paragraph! </P>\n",
      "<P>This is a another paragraph!</P>\n",
      "<B>This is a new sentence without a paragraph break, in bold italics.</B>\n",
      "<HR>\n",
      "</BODY>\n",
      "</HTML>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get(\n",
    "    \"https://raw.githubusercontent.com/selva86/datasets/master/sample.html\")\n",
    "print(r.text)  # html text is contained here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:22.510147Z",
     "start_time": "2021-03-01T06:20:22.505700Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_from_tag(html_text):\n",
    "    return re.findall(r'<.*>(.+)</.*>', html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:22.518063Z",
     "start_time": "2021-03-01T06:20:22.512724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Your Title Here',\n",
       " 'Link Name',\n",
       " 'This is a Header',\n",
       " 'This is a Medium Header',\n",
       " 'This is a new paragraph! ',\n",
       " 'This is a another paragraph!',\n",
       " 'This is a new sentence without a paragraph break, in bold italics.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_from_tag(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:22.771313Z",
     "start_time": "2021-03-01T06:20:22.520561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML>\n",
      "<HEAD>\n",
      "<TITLE>Your Title Here</TITLE>\n",
      "</HEAD>\n",
      "\n",
      "<BODY>\n",
      "<HR>\n",
      "<a href=\"http://someurl.com\">Link Name</a>\n",
      "<H1>This is a Header</H1>\n",
      "<H2>This is a Medium Header</H2>\n",
      "<P>This is a new paragraph! </P>\n",
      "<P>This is a another paragraph!</P>\n",
      "<B>This is a new sentence without a paragraph break, in bold italics.</B>\n",
      "<HR>\n",
      "</BODY>\n",
      "</HTML>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract P\n",
    "r = requests.get(\n",
    "    \"https://raw.githubusercontent.com/selva86/datasets/master/sample.html\")\n",
    "print(r.text)  # html text is contained here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:22.777599Z",
     "start_time": "2021-03-01T06:20:22.773831Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_from_tag(html_text):\n",
    "    return re.findall(r'<P>(.+)</P>', html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:22.784418Z",
     "start_time": "2021-03-01T06:20:22.780126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a new paragraph! ', 'This is a another paragraph!']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_from_tag(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:22.789002Z",
     "start_time": "2021-03-01T06:20:22.786577Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"python清理數據，僅保留字母，數字，中文，在前面加'ur'\n",
    "          u的意思是表明後面有Unicode字符，漢字的範圍為'\\u4e00-\\i9fa5\n",
    "          這個是用Unicode表示的\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:22.793467Z",
     "start_time": "2021-03-01T06:20:22.790780Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    rule = re.compile(r\"[^a-zA-Z0-9\\u4e00-\\u9fa5]\")\n",
    "    result = rule.sub('', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T06:20:22.802202Z",
     "start_time": "2021-03-01T06:20:22.795187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python清理數據僅保留字母數字中文在前面加uru的意思是表明後面有Unicode字符漢字的範圍為一i9fa5這個是用Unicode表示的'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuation(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T07:01:01.745115Z",
     "start_time": "2021-03-01T07:01:01.738958Z"
    },
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://pic.pimg.tw/happy78/1528543947-685380499_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543947-362759723_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543962-2265924582_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543962-4007835890_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543962-1785144547_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543960-3197815885_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543947-2503982521_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543950-1832601825_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543949-4214686345_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543955-3093638684_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543955-714147528_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543956-1850884036_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543959-4177938168_n.jpg',\n",
       " 'https://pic.pimg.tw/happy78/1528543947-685380499_n.png']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract img source in html plain text\n",
    "# https://stackoverflow.com/questions/1028362/how-do-i-extract-html-img-sources-with-a-regular-expression/1028370\n",
    "# regax 解釋\n",
    "# 擷取以`<img`\n",
    "# 開頭配對一個或是多個 []+\n",
    "# 並且非右鍵號 [^>]+\n",
    "# 直到遇到src=\"\n",
    "# 拿取裡面的\n",
    "with open('data/webpage_1.txt') as f:\n",
    "    text = f.read()\n",
    "# print(text)\n",
    "# add the other extension(like png, tiff, ...)\n",
    "text += '<img alt=\"IMG_5208.png\" src=\"https://pic.pimg.tw/happy78/1528543947-685380499_n.png\" title=\"IMG_5208.png\">'\n",
    "text += '<img alt=\"IMG_5208.png\" src=\"https://pic.pimg.tw/happy78/1528543947-685380499_n.tiff\" title=\"IMG_5208.png\">'\n",
    "pat = re.compile('<img[^>]+src=\"([^\">]+[jpg|png])\"')\n",
    "pat.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
